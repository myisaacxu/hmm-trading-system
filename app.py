#!/usr/bin/env python3
"""
å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«ç³»ç»Ÿ - é¡¹ç›®å¯åŠ¨ç¨‹åº

åŸºäºéšé©¬å°”å¯å¤«æ¨¡å‹(HMM)çš„é“¶è¡Œè‚¡å¸‚åœºçŠ¶æ€è¯†åˆ«ä¸äº¤æ˜“ç­–ç•¥åº”ç”¨ã€‚
ç³»ç»Ÿä½¿ç”¨baostockè·å–å…‰å¤§é“¶è¡Œå†å²æ•°æ®ï¼Œç»“åˆakshareè·å–çš„å®è§‚æ•°æ®ï¼Œ
å®ç°å®Œæ•´çš„å¸‚åœºçŠ¶æ€è¯†åˆ«ä¸äº¤æ˜“ç­–ç•¥å›æµ‹åŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•:
    streamlit run app.py

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import warnings
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œç¡®ä¿æ¨¡å—å¯¼å…¥æ­£å¸¸
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from src.utils.logger import global_logger

try:
    import streamlit as st
    import pandas as pd
    import numpy as np
    import baostock as bs
    import akshare as ak
    from hmmlearn import hmm
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import plotly.express as px
    import joblib
    import json
    from datetime import datetime, timedelta
    from typing import Optional, Dict, Tuple, List

    # å¯¼å…¥é¡¹ç›®æ¨¡å—
    try:
        from src.data.data_fetcher import DataFetcher
        from src.features.feature_engineer import FeatureEngineer
        from src.models.market_state_analyzer import MarketStateAnalyzer
        from src.models.model_manager import ModelManager

        MODULE_IMPORT_SUCCESS = True
    except ImportError as e:
        st.warning(f"æ¨¡å—å¯¼å…¥è­¦å‘Š: {e}")
        st.info("æ­£åœ¨ä½¿ç”¨å¤‡ç”¨æ¨¡å¼è¿è¡Œ...")
        MODULE_IMPORT_SUCCESS = False

except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ… - {e}")
    print("\nè¯·å®‰è£…ä»¥ä¸‹ä¾èµ–åŒ…:")
    print("pip install streamlit pandas numpy baostock akshare hmmlearn plotly joblib")
    sys.exit(1)


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å·²å®‰è£…"""
    required_packages = [
        "streamlit",
        "pandas",
        "numpy",
        "baostock",
        "akshare",
        "hmmlearn",
        "plotly",
        "joblib",
    ]

    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)

    return missing_packages


def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    models_dir = current_dir / "models"
    models_dir.mkdir(exist_ok=True)
    global_logger.info(f"å·²åˆ›å»ºæˆ–ç¡®è®¤æ¨¡å‹ç›®å½•: {models_dir}")

    logs_dir = current_dir / "logs"
    logs_dir.mkdir(exist_ok=True)
    global_logger.info(f"å·²åˆ›å»ºæˆ–ç¡®è®¤æ—¥å¿—ç›®å½•: {logs_dir}")


def get_ebs_data():
    """è·å–è‚¡å€ºåˆ©å·®æ•°æ®"""
    try:
        ebs_df = ak.stock_ebs_lg()

        if ebs_df.empty:
            st.error("è·å–çš„è‚¡å€ºåˆ©å·®æ•°æ®ä¸ºç©º")
            return None

        ebs_df = ebs_df.rename(columns={"æ—¥æœŸ": "date", "è‚¡å€ºåˆ©å·®": "ebs_indicator"})
        ebs_df = ebs_df[["date", "ebs_indicator"]]
        ebs_df["ebs_indicator"] = ebs_df["ebs_indicator"] * 100

        ebs_df["date"] = pd.to_datetime(ebs_df["date"])
        ebs_df = ebs_df.set_index("date").sort_index()

        return ebs_df["ebs_indicator"]

    except Exception as e:
        st.error(f"è·å–è‚¡å€ºåˆ©å·®æ•°æ®å¤±è´¥: {e}")
        return None


def get_buffett_index():
    """è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®"""
    try:
        # ä¼˜å…ˆä½¿ç”¨akshareçš„ç›´æ¥æ¥å£è·å–å·´è²ç‰¹æŒ‡æ•°
        buffett_df = ak.stock_buffett_index_lg()

        if not buffett_df.empty:
            # é‡å‘½åå’Œæ ¼å¼åŒ–
            buffett_df = buffett_df.rename(columns={"æ—¥æœŸ": "date"})

            # è®¡ç®—å·´è²ç‰¹æŒ‡æ•°ï¼šæ€»å¸‚å€¼/GDP * 100
            if "æ€»å¸‚å€¼" in buffett_df.columns and "GDP" in buffett_df.columns:
                buffett_df["buffett_index"] = (
                    buffett_df["æ€»å¸‚å€¼"] / buffett_df["GDP"]
                ) * 100
            else:
                # å¦‚æœåˆ—åä¸åŒï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—åç»„åˆ
                if "market_cap" in buffett_df.columns and "gdp" in buffett_df.columns:
                    buffett_df["buffett_index"] = (
                        buffett_df["market_cap"] / buffett_df["gdp"]
                    ) * 100
                else:
                    # ä½¿ç”¨é»˜è®¤çš„å·´è²ç‰¹æŒ‡æ•°åˆ—
                    buffett_df["buffett_index"] = (
                        buffett_df.iloc[:, 1] if len(buffett_df.columns) > 1 else 100
                    )

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            buffett_df["date"] = pd.to_datetime(buffett_df["date"])

            # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•å¹¶æ’åº
            buffett_df.set_index("date", inplace=True)
            buffett_df = buffett_df.sort_index()

            return buffett_df["buffett_index"]
        else:
            # å¦‚æœç›´æ¥æ¥å£å¤±è´¥ï¼Œå›é€€åˆ°ç»„åˆè®¡ç®—æ–¹å¼
            return _calculate_buffett_index_fallback()

    except Exception as e:
        st.warning(f"è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•: {e}")
        # ä½¿ç”¨å¤‡ç”¨è®¡ç®—æ–¹å¼
        return _calculate_buffett_index_fallback()


def _calculate_buffett_index_fallback():
    """å¤‡ç”¨æ–¹æ³•ï¼šæ‰‹åŠ¨è®¡ç®—å·´è²ç‰¹æŒ‡æ•°"""
    try:
        # ä½¿ç”¨akshareè·å–GDPå’Œå¸‚å€¼æ•°æ®
        gdp_df = ak.macro_china_gdp()
        market_cap_df = ak.macro_china_stock_market_cap()

        if gdp_df.empty or market_cap_df.empty:
            st.warning("æ— æ³•è·å–å®Œæ•´çš„å·´è²ç‰¹æŒ‡æ•°æ•°æ®")
            return None

        # å¤„ç†å¸‚å€¼æ•°æ®
        if not market_cap_df.empty:
            latest_market_cap = market_cap_df.iloc[0]
            shanghai_market_cap = latest_market_cap.get("å¸‚ä»·æ€»å€¼-ä¸Šæµ·", 0)
            shenzhen_market_cap = latest_market_cap.get("å¸‚ä»·æ€»å€¼-æ·±åœ³", 0)

            if pd.notna(shanghai_market_cap) and pd.notna(shenzhen_market_cap):
                total_market_cap = shanghai_market_cap + shenzhen_market_cap
            else:
                total_market_cap = None
        else:
            total_market_cap = None

        # è·å–æœ€æ–°çš„GDPæ•°æ®
        latest_gdp = gdp_df.iloc[0] if not gdp_df.empty else None

        if latest_gdp is not None and "value" in latest_gdp:
            current_gdp = latest_gdp["value"]

            # è®¡ç®—å·´è²ç‰¹æŒ‡æ•° = æ€»å¸‚å€¼ / GDP
            buffett_index_value = (
                (total_market_cap / current_gdp) * 100
                if current_gdp > 0 and total_market_cap is not None
                else 100
            )

            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®ï¼Œä½¿ç”¨æ—¥é¢‘ç‡ä»¥åŒ¹é…è‚¡ç¥¨æ•°æ®
            dates = pd.date_range(start="2010-01-01", end=datetime.now(), freq="D")
            buffett_values = np.full(len(dates), buffett_index_value)

            return pd.Series(buffett_values, index=dates, name="buffett_index")
        else:
            # GDPæ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            dates = pd.date_range(start="2010-01-01", end=datetime.now(), freq="D")
            buffett_values = np.linspace(80, 120, len(dates))

            return pd.Series(buffett_values, index=dates, name="buffett_index")

    except Exception as e:
        st.warning(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        # è¿”å›é»˜è®¤æ•°æ®ï¼Œä½¿ç”¨æ›´åˆç†çš„èŒƒå›´80-120è€Œä¸æ˜¯å›ºå®šçš„150
        dates = pd.date_range(start="2010-01-01", end=datetime.now(), freq="D")
        buffett_values = np.linspace(80, 120, len(dates))

        return pd.Series(buffett_values, index=dates, name="buffett_index")


def get_cebbank_data(start_date: str, end_date: str = None) -> Optional[pd.DataFrame]:
    """è·å–å…‰å¤§é“¶è¡Œè‚¡ç¥¨æ•°æ®"""
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")

    try:
        # ç™»å½•baostock
        bs.login()

        # æŸ¥è¯¢å…‰å¤§é“¶è¡Œ(601818)æ•°æ®
        rs = bs.query_history_k_data_plus(
            "sh.601818",
            "date,code,open,high,low,close,preclose,volume,amount,turn,pctChg",
            start_date=start_date,
            end_date=end_date,
            frequency="d",
            adjustflag="3",
        )

        data_list = []
        while (rs.error_code == "0") & rs.next():
            data_list.append(rs.get_row_data())

        result = pd.DataFrame(data_list, columns=rs.fields)

        if result.empty:
            st.error("è·å–çš„å…‰å¤§é“¶è¡Œæ•°æ®ä¸ºç©º")
            return None

        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_cols = [
            "open",
            "high",
            "low",
            "close",
            "preclose",
            "volume",
            "amount",
            "turn",
            "pctChg",
        ]
        for col in numeric_cols:
            result[col] = pd.to_numeric(result[col], errors="coerce")

        result["date"] = pd.to_datetime(result["date"])
        result = result.set_index("date").sort_index()

        # ç™»å‡ºbaostock
        bs.logout()

        return result

    except Exception as e:
        st.error(f"è·å–å…‰å¤§é“¶è¡Œæ•°æ®å¤±è´¥: {e}")
        try:
            bs.logout()
        except Exception:
            pass
        return None


def calculate_technical_indicators(
    price_series: pd.Series,
    vol_window: int = 30,
    ma_short: int = 20,
    ma_long: int = 100,
) -> pd.DataFrame:
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    price_series = price_series[~price_series.index.duplicated(keep="first")]
    price_series = price_series.sort_index().ffill().bfill().fillna(0.0)

    # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡
    lr = np.log(price_series).diff().fillna(0.0)
    vol = lr.rolling(vol_window, min_periods=1).std().fillna(0.0)

    # è®¡ç®—å‡çº¿å’Œè¶‹åŠ¿æŒ‡æ ‡
    ma_short = price_series.rolling(ma_short).mean().bfill()
    ma_long = price_series.rolling(ma_long).mean().bfill()
    spread = ((ma_short - ma_long) / ma_long).fillna(0.0)

    tech_df = pd.DataFrame(
        {
            "PX": price_series,
            "log_ret": lr,
            "VOL": vol,
            "MA_SHORT": ma_short,
            "MA_LONG": ma_long,
            "SPREAD": spread,
        }
    )

    return tech_df


def align_macro_data(
    tech_df: pd.DataFrame,
    ebs_data: Optional[pd.Series] = None,
    buffett_data: Optional[pd.Series] = None,
) -> pd.DataFrame:
    """å¯¹é½å®è§‚æ•°æ®"""
    features_df = tech_df.copy()

    # å¯¹é½è‚¡å€ºåˆ©å·®æ•°æ®
    if ebs_data is not None:
        ebs_aligned = ebs_data.reindex(features_df.index, method="ffill")
        features_df["EBS"] = ebs_aligned.fillna(0.0)
    else:
        features_df["EBS"] = 0.0

    # å¯¹é½å·´è²ç‰¹æŒ‡æ•°æ•°æ®
    if buffett_data is not None:
        buffett_aligned = buffett_data.reindex(features_df.index, method="ffill")
        features_df["BUFFETT"] = buffett_aligned.fillna(0.0)
    else:
        features_df["BUFFETT"] = 0.0

    return features_df


def create_feature_matrix(
    features_df: pd.DataFrame, use_standardization: bool = True
) -> Tuple[np.ndarray, np.ndarray]:
    """åˆ›å»ºç‰¹å¾çŸ©é˜µ"""
    feature_cols = ["log_ret", "VOL", "SPREAD", "EBS", "BUFFETT"]

    if not all(col in features_df.columns for col in feature_cols):
        st.error("ç‰¹å¾æ•°æ®ä¸å®Œæ•´")
        return np.array([]), np.array([])

    X = features_df[feature_cols].values
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

    # Z-åˆ†æ•°æ ‡å‡†åŒ–
    Xz = X.copy()
    if use_standardization and len(X) > 1:
        X_mean = X.mean(axis=0, keepdims=True)
        X_std = X.std(axis=0, keepdims=True) + 1e-12
        Xz = (X - X_mean) / X_std

    return X, Xz


def train_hmm_model(
    X: np.ndarray, n_states: int = 3, min_duration: int = 10, stickiness: float = 5.0
) -> Dict:
    """è®­ç»ƒHMMæ¨¡å‹"""
    if len(X) == 0:
        return {}

    try:
        # è®­ç»ƒé«˜æ–¯HMMæ¨¡å‹
        model = hmm.GaussianHMM(
            n_components=n_states, covariance_type="full", n_iter=100, random_state=42
        )

        model.fit(X)

        # é¢„æµ‹çŠ¶æ€
        labels = model.predict(X)

        # çŠ¶æ€å¹³æ»‘
        labels = enforce_min_duration(labels, min_duration)

        return {"model": model, "labels": labels, "n_states": n_states}

    except Exception as e:
        st.error(f"HMMæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return {}


def enforce_min_duration(labels: np.ndarray, min_len: int) -> np.ndarray:
    """å¼ºåˆ¶æœ€å°çŠ¶æ€æŒç»­æ—¶é—´"""
    if len(labels) == 0:
        return labels

    smoothed = labels.copy()

    # æ‰¾å‡ºæ‰€æœ‰çŠ¶æ€å˜åŒ–çš„ç‚¹
    change_points = np.where(np.diff(smoothed) != 0)[0] + 1
    change_points = np.concatenate(([0], change_points, [len(smoothed)]))

    # åˆå¹¶çŸ­çŠ¶æ€
    for i in range(len(change_points) - 1):
        start = change_points[i]
        end = change_points[i + 1]
        duration = end - start

        if duration < min_len and i > 0:
            # çŸ­çŠ¶æ€åˆå¹¶åˆ°å‰ä¸€ä¸ªçŠ¶æ€
            smoothed[start:end] = smoothed[start - 1]

    return smoothed


def generate_trading_signals(
    price_data: pd.DataFrame, labels: np.ndarray, state_names: List[str] = None
) -> pd.DataFrame:
    """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
    if state_names is None:
        state_names = [f"State_{i}" for i in range(len(np.unique(labels)))]

    signals = price_data.copy()
    signals["regime"] = [state_names[i] for i in labels]

    # ç”Ÿæˆäº¤æ˜“ä¿¡å·
    signals["position"] = 0
    signals.loc[signals["regime"].str.contains("Bull"), "position"] = 1
    signals.loc[signals["regime"].str.contains("Bear"), "position"] = -1

    # è®¡ç®—ç­–ç•¥æ”¶ç›Šç‡
    signals["log_ret"] = np.log(signals["close"]).diff().fillna(0.0)
    signals["strat_ret"] = signals["position"] * signals["log_ret"]

    return signals


def calculate_performance_metrics(signals: pd.DataFrame) -> Dict:
    """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
    if signals.empty:
        return {}

    # ä¹°å…¥æŒæœ‰ç­–ç•¥
    bh_cum_ret = np.exp(signals["log_ret"].cumsum())
    bh_final_ret = bh_cum_ret.iloc[-1] - 1

    # HMMç­–ç•¥
    strat_cum_ret = np.exp(signals["strat_ret"].cumsum())
    strat_final_ret = strat_cum_ret.iloc[-1] - 1

    # å¹´åŒ–æ”¶ç›Šç‡
    days = len(signals)
    years = days / 252

    bh_cagr = (1 + bh_final_ret) ** (1 / years) - 1 if years > 0 else 0
    strat_cagr = (1 + strat_final_ret) ** (1 / years) - 1 if years > 0 else 0

    # å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
    bh_sharpe = (
        bh_cagr / (signals["log_ret"].std() * np.sqrt(252))
        if signals["log_ret"].std() > 0
        else 0
    )
    strat_sharpe = (
        strat_cagr / (signals["strat_ret"].std() * np.sqrt(252))
        if signals["strat_ret"].std() > 0
        else 0
    )

    return {
        "buy_hold": {
            "cagr": bh_cagr,
            "sharpe": bh_sharpe,
            "final_return": bh_final_ret,
        },
        "hmm_strategy": {
            "cagr": strat_cagr,
            "sharpe": strat_sharpe,
            "final_return": strat_final_ret,
        },
    }


def create_price_chart(price_data: pd.DataFrame, labels: np.ndarray) -> go.Figure:
    """åˆ›å»ºä»·æ ¼èµ°åŠ¿å›¾"""
    fig = go.Figure()

    # ä»·æ ¼èµ°åŠ¿
    fig.add_trace(
        go.Scatter(
            x=price_data.index,
            y=price_data["close"],
            mode="lines",
            name="å…‰å¤§é“¶è¡Œæ”¶ç›˜ä»·",
            line=dict(color="blue", width=2),
        )
    )

    # æ·»åŠ çŠ¶æ€åŒºåŸŸ
    unique_states = np.unique(labels)
    colors = ["green", "red", "gray", "orange", "purple"]

    for i, state in enumerate(unique_states):
        mask = labels == state
        state_dates = price_data.index[mask]

        if len(state_dates) > 0:
            fig.add_vrect(
                x0=state_dates[0],
                x1=state_dates[-1],
                fillcolor=colors[i % len(colors)],
                opacity=0.2,
                layer="below",
                line_width=0,
                annotation_text=f"State {state}",
                annotation_position="top left",
            )

    fig.update_layout(
        title="å…‰å¤§é“¶è¡Œä»·æ ¼èµ°åŠ¿ä¸å¸‚åœºçŠ¶æ€è¯†åˆ«",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="ä»·æ ¼(å…ƒ)",
        height=400,
    )

    return fig


def main():
    """ä¸»å‡½æ•°"""
    # è®°å½•åº”ç”¨å¯åŠ¨
    global_logger.info("å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«ç³»ç»Ÿå¯åŠ¨")
    
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«",
        page_icon="ğŸ¦",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # åº”ç”¨æ ‡é¢˜
    st.title("ğŸ¦ å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«ç³»ç»Ÿ")
    st.markdown("åŸºäºéšé©¬å°”å¯å¤«æ¨¡å‹(HMM)çš„é“¶è¡Œè‚¡å¸‚åœºçŠ¶æ€è¯†åˆ«ä¸äº¤æ˜“ç­–ç•¥")

    # ä¾§è¾¹æ é…ç½®å‚æ•°
    st.sidebar.header("ç­–ç•¥å‚æ•°é…ç½®")

    # asset = st.sidebar.selectbox("é€‰æ‹©èµ„äº§", ["å…‰å¤§é“¶è¡Œ(601818)"], index=0)
    start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", pd.to_datetime("2010-01-01"))
    n_states = st.sidebar.slider("çŠ¶æ€æ•°é‡", 2, 6, 3)
    min_len = st.sidebar.slider("æœ€å°çŠ¶æ€æŒç»­æ—¶é—´", 5, 30, 15)
    stickiness = st.sidebar.slider("çŠ¶æ€ç²˜æ€§", 1.0, 20.0, 8.0)

    # é“¶è¡Œè‚¡ä¸“ç”¨å‚æ•°
    st.sidebar.markdown("---")
    st.sidebar.header("é“¶è¡Œè‚¡ä¸“ç”¨å‚æ•°")
    vol_window = st.sidebar.slider("æ³¢åŠ¨ç‡è®¡ç®—çª—å£", 10, 60, 30)
    ma_short = st.sidebar.slider("çŸ­æœŸå‡çº¿çª—å£", 10, 50, 20)
    ma_long = st.sidebar.slider("é•¿æœŸå‡çº¿çª—å£", 50, 200, 100)

    end = None
    
    global_logger.info(f"ç­–ç•¥å‚æ•°é…ç½®å®Œæˆ: å¼€å§‹æ—¥æœŸ={start_date}, çŠ¶æ€æ•°é‡={n_states}, æœ€å°çŠ¶æ€æŒç»­æ—¶é—´={min_len}, çŠ¶æ€ç²˜æ€§={stickiness}")

    # æ˜¾ç¤ºè¿›åº¦
    with st.spinner("æ­£åœ¨è·å–æ•°æ®å¹¶è®¡ç®—..."):
        # ä¸‹è½½å…‰å¤§é“¶è¡Œæ•°æ®
        global_logger.info(f"å¼€å§‹è·å–å…‰å¤§é“¶è¡Œæ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {start_date} åˆ° {end}")
        df_cebbank = get_cebbank_data(start_date.strftime("%Y-%m-%d"), end)

        if df_cebbank is None or df_cebbank.empty:
            st.error("æ— æ³•è·å–å…‰å¤§é“¶è¡Œæ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ—¥æœŸèŒƒå›´")
            global_logger.error("æ— æ³•è·å–å…‰å¤§é“¶è¡Œæ•°æ®")
            st.stop()
        
        global_logger.info(f"æˆåŠŸè·å–å…‰å¤§é“¶è¡Œæ•°æ®ï¼Œæ•°æ®é•¿åº¦: {len(df_cebbank)}")

        px_series = df_cebbank["close"].rename("PX")

        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
        px_series = px_series[~px_series.index.duplicated(keep="first")]

        # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡ç‰¹å¾ï¼ˆé’ˆå¯¹é“¶è¡Œè‚¡ä¼˜åŒ–ï¼‰
        global_logger.info("å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡")
        lr = np.log(px_series).diff().fillna(0.0)  # å¯¹æ•°æ”¶ç›Šç‡
        vol = lr.rolling(vol_window, min_periods=1).std().fillna(0.0)  # å¯è°ƒæ³¢åŠ¨ç‡çª—å£
        ma_short_series = px_series.rolling(ma_short).mean().bfill()
        ma_long_series = px_series.rolling(ma_long).mean().bfill()
        spread = ((ma_short_series - ma_long_series) / ma_long_series).fillna(
            0.0
        )  # å¯è°ƒè¶‹åŠ¿æŒ‡æ ‡
        global_logger.info("æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")

        # è·å–è‚¡å€ºåˆ©å·®æ•°æ®
        global_logger.info("å¼€å§‹è·å–è‚¡å€ºåˆ©å·®æ•°æ®")
        ebs_data = get_ebs_data()
        if ebs_data is not None:
            # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
            ebs_data = ebs_data[~ebs_data.index.duplicated(keep="first")]
            ebs_data = ebs_data.reindex(px_series.index, method="ffill")  # å¯¹é½æ—¥æœŸç´¢å¼•
            global_logger.info("æˆåŠŸè·å–å¹¶å¯¹é½è‚¡å€ºåˆ©å·®æ•°æ®")
        else:
            # å¦‚æœè·å–å¤±è´¥ï¼Œåˆ›å»ºç©ºçš„è‚¡å€ºåˆ©å·®åˆ—
            ebs_data = pd.Series(0.0, index=px_series.index, name="ebs_indicator")
            global_logger.warning("æ— æ³•è·å–è‚¡å€ºåˆ©å·®æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")

        # è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®
        global_logger.info("å¼€å§‹è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®")
        buffett_data = get_buffett_index()
        if buffett_data is not None:
            # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
            buffett_data = buffett_data[~buffett_data.index.duplicated(keep="first")]
            # ç¡®ä¿æ•°æ®èŒƒå›´ä¸è‚¡ç¥¨æ•°æ®åŒ¹é…
            if len(buffett_data) > 0:
                # è·å–ä¸è‚¡ç¥¨æ•°æ®æ—¥æœŸèŒƒå›´é‡å çš„éƒ¨åˆ†
                buffett_in_range = buffett_data[
                    (buffett_data.index >= px_series.index.min())
                    & (buffett_data.index <= px_series.index.max())
                ]

                if len(buffett_in_range) > 0:
                    # ä½¿ç”¨å‰å‘å¡«å……å¯¹é½åˆ°è‚¡ç¥¨æ•°æ®ç´¢å¼•
                    buffett_aligned = buffett_in_range.reindex(
                        px_series.index, method="ffill"
                    )
                    buffett_data = buffett_aligned.fillna(method="bfill").fillna(
                        buffett_in_range.mean() if not buffett_in_range.empty else 100.0
                    )
                else:
                    # å¦‚æœæ•°æ®èŒƒå›´ä¸é‡å ï¼Œä½¿ç”¨æœ€è¿‘çš„å€¼
                    buffett_data = pd.Series(
                        buffett_data.iloc[-1] if not buffett_data.empty else 100.0,
                        index=px_series.index,
                        name="buffett_index",
                    )
            else:
                buffett_data = pd.Series(
                    100.0, index=px_series.index, name="buffett_index"
                )
            global_logger.info("æˆåŠŸè·å–å¹¶å¯¹é½å·´è²ç‰¹æŒ‡æ•°æ•°æ®")
        else:
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨åˆç†çš„é»˜è®¤å€¼è€Œä¸æ˜¯0.0
            buffett_data = pd.Series(100.0, index=px_series.index, name="buffett_index")
            global_logger.warning("æ— æ³•è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")

        # åˆ›å»ºç‰¹å¾æ•°æ®æ¡†
        df = pd.DataFrame(
            {
                "PX": px_series,
                "VOL": vol,
                "SPREAD": spread,
                "EBS": (
                    ebs_data["ebs_indicator"]
                    if isinstance(ebs_data, pd.DataFrame)
                    else ebs_data
                ),
                "BUFFETT": (
                    buffett_data["buffett_index"]
                    if isinstance(buffett_data, pd.DataFrame)
                    else buffett_data
                ),
            }
        ).dropna()

        # ç¡®ä¿æ—¥æœŸç´¢å¼•å¯¹é½
        df = df.sort_index()
        global_logger.info(f"ç‰¹å¾æ•°æ®æ¡†åˆ›å»ºå®Œæˆï¼Œæ•°æ®é•¿åº¦: {len(df)}")

        # è®¾è®¡çŸ©é˜µï¼ˆè¡Œå¯¹åº” df.indexï¼‰
        X = np.column_stack(
            [
                np.log(df["PX"]).diff().fillna(0.0).values,  # å¯¹æ•°æ”¶ç›Šç‡
                df["VOL"].values,  # æ³¢åŠ¨ç‡
                df["SPREAD"].values,  # è¶‹åŠ¿æŒ‡æ ‡
                df["EBS"].values,  # è‚¡å€ºåˆ©å·®
                df["BUFFETT"].values,  # å·´è²ç‰¹æŒ‡æ•°
            ]
        )
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

        # å¯é€‰ï¼šZ-åˆ†æ•°æ ‡å‡†åŒ–ï¼Œæé«˜çŠ¶æ€åŒºåˆ†åº¦
        X_mean = X.mean(axis=0, keepdims=True)
        X_std = X.std(axis=0, keepdims=True) + 1e-12
        Xz = (X - X_mean) / X_std

        # æ ¸å¿ƒé€»è¾‘ â€” HMM ç±»ä¸å¹³æ»‘å¤„ç†
        class HMMRegimeDetector:
            def __init__(
                self,
                n_states=4,
                covariance_type="diag",
                n_iter=300,
                tol=1e-4,
                random_state=None,
            ):
                self.model = hmm.GaussianHMM(
                    n_components=n_states,
                    covariance_type=covariance_type,
                    n_iter=n_iter,
                    tol=tol,
                    random_state=random_state,
                )
                self.n_states = n_states

            @staticmethod
            def enforce_min_duration(labels, min_len=10):
                """åˆå¹¶çŸ­çŠ¶æ€è¿è¡Œï¼ˆ< min_lenï¼‰åˆ°è¾ƒé•¿çš„ç›¸é‚»çŠ¶æ€"""
                s = np.array(labels, copy=True)
                n = len(s)
                i = 0
                while i < n:
                    j = i + 1
                    while j < n and s[j] == s[i]:
                        j += 1
                    run_len = j - i
                    if run_len < min_len:
                        left = s[i - 1] if i > 0 else None
                        right = s[j] if j < n else None
                        if left is None and right is not None:
                            s[i:j] = right
                        elif right is None and left is not None:
                            s[i:j] = left
                        elif left is not None and right is not None:
                            # æ¯”è¾ƒç›¸é‚»è¿è¡Œçš„é•¿åº¦
                            L = i - 1
                            while L - 1 >= 0 and s[L - 1] == left:
                                L -= 1
                            left_len = i - L
                            R = j
                            while R + 1 < n and s[R + 1] == right:
                                R += 1
                            right_len = R - j + 1
                            s[i:j] = left if left_len >= right_len else right
                    i = j
                return s

            def fit(self, X):
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore")
                    self.model.fit(X)
                return self

            def make_sticky(self, strength=10.0):
                """é€šè¿‡å¢å¼ºè½¬ç§»çŸ©é˜µå¯¹è§’çº¿ä½¿çŠ¶æ€æ›´å€¾å‘äºä¿æŒä¸å˜"""
                A = self.model.transmat_
                A = A + strength * np.eye(self.n_states)
                self.model.transmat_ = A / A.sum(axis=1, keepdims=True)
                return self

            def predict(self, X, min_len=10, sticky_strength=None):
                if sticky_strength is not None:
                    self.make_sticky(sticky_strength)
                states = self.model.predict(X)
                states = self.enforce_min_duration(states, min_len=min_len)
                proba = self.model.predict_proba(X)
                return states, proba

        # æ‰§è¡Œå’Œç»“æœï¼ˆè®­ç»ƒã€æ ‡è®°ã€ç»˜å›¾ã€ç®€å•å›æµ‹ï¼‰
        # åœ¨æ ‡å‡†åŒ–ç‰¹å¾ä¸Šè®­ç»ƒ HMM
        global_logger.info(f"å¼€å§‹è®­ç»ƒHMMæ¨¡å‹ï¼ŒçŠ¶æ€æ•°é‡: {n_states}")
        detector = HMMRegimeDetector(n_states=n_states).fit(Xz)
        global_logger.info("HMMæ¨¡å‹è®­ç»ƒå®Œæˆ")

        # ä½¿ç”¨ç²˜æ€§å’Œæœ€å°æŒç»­æ—¶é—´å¹³æ»‘é¢„æµ‹çŠ¶æ€
        global_logger.info(f"å¼€å§‹é¢„æµ‹å¸‚åœºçŠ¶æ€ï¼Œæœ€å°æŒç»­æ—¶é—´: {min_len}, çŠ¶æ€ç²˜æ€§: {stickiness}")
        states, proba = detector.predict(
            Xz, min_len=min_len, sticky_strength=stickiness
        )
        global_logger.info(f"å¸‚åœºçŠ¶æ€é¢„æµ‹å®Œæˆï¼Œå…±è¯†åˆ« {len(np.unique(states))} ç§çŠ¶æ€")

        # ç»„è£…è¾“å‡ºæ•°æ®æ¡†
        out = df.copy()
        out["log_ret"] = np.log(df["PX"]).diff().fillna(0.0)
        out["state"] = states

        # æŒ‰å¹³å‡æ”¶ç›Šç‡æ’åºçŠ¶æ€å¹¶æ˜ å°„åˆ°å¸‚åœºçŠ¶æ€
        state_means = (
            out.groupby("state")["log_ret"].mean().sort_values(ascending=False)
        )
        ranked = state_means.index.tolist()
        labels = {ranked[0]: "Bull", ranked[-1]: "Bear"}
        for s in set(range(n_states)) - set(labels):
            labels[s] = "Neutral"
        out["regime"] = out["state"].map(labels)
        
        # è®°å½•çŠ¶æ€æ˜ å°„
        global_logger.info(f"çŠ¶æ€æ˜ å°„å®Œæˆ: {labels}")

        # ç®€å•çŠ¶æ€äº¤æ˜“å›æµ‹ï¼ˆä»…ç”¨äºç›´è§‚ç†è§£ï¼Œéæ‰§è¡Œçº§åˆ«ï¼‰
        # ç‰›å¸‚åšå¤šï¼Œç†Šå¸‚åšç©ºï¼Œä¸­æ€§å¸‚åœºè§‚æœ›ï¼›ç¬¬äºŒå¤©æ‰§è¡Œäº¤æ˜“ï¼ˆç§»ä½æŒä»“ï¼‰
        global_logger.info("å¼€å§‹ç”Ÿæˆäº¤æ˜“ä¿¡å·")
        out["position"] = 0
        out.loc[out["regime"] == "Bull", "position"] = 1
        out.loc[out["regime"] == "Bear", "position"] = -1

        # åº”ç”¨æ¬¡æ—¥æ‰§è¡Œ
        out["position"] = out["position"].shift(1).fillna(0)
        global_logger.info("äº¤æ˜“ä¿¡å·ç”Ÿæˆå®Œæˆ")

        # ç­–ç•¥å¯¹æ•°æ”¶ç›Šç‡å’Œç´¯ç§¯å¢é•¿ï¼ˆå¯¹æ•°/æŒ‡æ•°ç”¨äºæ•°å€¼ç¨³å®šæ€§ï¼‰
        out["strat_lr"] = out["position"] * out["log_ret"]
        cum = np.exp(out[["log_ret", "strat_lr"]].cumsum())
        cum.columns = ["BuyHold", "HMM_Strategy"]

        # ç®€å•æŒ‡æ ‡è®¡ç®—
        def sharpe(x, periods=252):
            mu, sd = x.mean(), x.std()
            return (mu / sd) * np.sqrt(periods) if sd > 0 else np.nan

        def max_drawdown(series):
            rollmax = series.cummax()
            dd = series / rollmax - 1.0
            return dd.min()

        bh_cagr = cum["BuyHold"].iloc[-1] ** (252 / len(out)) - 1
        st_cagr = cum["HMM_Strategy"].iloc[-1] ** (252 / len(out)) - 1
        bh_sharp = sharpe(out["log_ret"])
        st_sharp = sharpe(out["strat_lr"])
        bh_mdd = max_drawdown(cum["BuyHold"])
        st_mdd = max_drawdown(cum["HMM_Strategy"])
        
        # è®°å½•ç­–ç•¥è¡¨ç°
        global_logger.info(f"ç­–ç•¥è¡¨ç°è®¡ç®—å®Œæˆ: \
            ä¹°å…¥æŒæœ‰å¹´åŒ–æ”¶ç›Š: {bh_cagr:.2%}, \
            HMMç­–ç•¥å¹´åŒ–æ”¶ç›Š: {st_cagr:.2%}, \
            ä¹°å…¥æŒæœ‰å¤æ™®æ¯”ç‡: {bh_sharp:.2f}, \
            HMMç­–ç•¥å¤æ™®æ¯”ç‡: {st_sharp:.2f}")

        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å½“å‰å¸‚åœºçŠ¶æ€", out["regime"].iloc[-1])
        col2.metric("å…‰å¤§é“¶è¡Œä»·æ ¼", f"{out['PX'].iloc[-1]:.2f}")
        col3.metric("è‚¡å€ºåˆ©å·®", f"{out['EBS'].iloc[-1]:.2f}%")
        col4.metric("å·´è²ç‰¹æŒ‡æ•°", f"{out['BUFFETT'].iloc[-1]:.2f}")
        
        # è®°å½•å½“å‰å¸‚åœºçŠ¶æ€
        global_logger.log_market_state(
            timestamp=out.index[-1],
            state=out["regime"].iloc[-1],
            confidence=proba[-1, states[-1]] if len(proba) > 0 else None
        )

        # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºä¸åŒå›¾è¡¨
        tab1, tab2, tab3, tab4 = st.tabs(
            ["å…‰å¤§é“¶è¡Œèµ°åŠ¿", "æŒ‡æ ‡åˆ†æ", "ç­–ç•¥è¡¨ç°", "çŠ¶æ€ç»Ÿè®¡"]
        )

        with tab1:
            # å…‰å¤§é“¶è¡Œèµ°åŠ¿ä¸å¸‚åœºçŠ¶æ€
            fig = make_subplots(
                rows=2,
                cols=1,
                shared_xaxes=True,
                vertical_spacing=0.05,
                subplot_titles=("å…‰å¤§é“¶è¡Œä»·æ ¼", "å¸‚åœºçŠ¶æ€"),
            )

            # æ·»åŠ ä»·æ ¼çº¿
            fig.add_trace(
                go.Scatter(
                    x=out.index,
                    y=out["PX"],
                    name="å…‰å¤§é“¶è¡Œ",
                    line=dict(color="#1f77b4"),
                ),
                row=1,
                col=1,
            )

            # æ·»åŠ å¸‚åœºçŠ¶æ€èƒŒæ™¯
            colors = {"Bull": "#2ca02c", "Bear": "#d62728", "Neutral": "#ff7f0e"}
            prev_regime = None
            start_idx = out.index[0]

            for i, (date, regime) in enumerate(out["regime"].items()):
                if prev_regime is None:
                    prev_regime = regime
                    continue

                if regime != prev_regime:
                    # æ·»åŠ çŸ©å½¢åŒºåŸŸ
                    fig.add_vrect(
                        x0=start_idx,
                        x1=date,
                        fillcolor=colors[prev_regime],
                        opacity=0.2,
                        line_width=0,
                        row=1,
                        col=1,
                    )
                    fig.add_vrect(
                        x0=start_idx,
                        x1=date,
                        fillcolor=colors[prev_regime],
                        opacity=0.2,
                        line_width=0,
                        row=2,
                        col=1,
                    )
                    start_idx = date
                    prev_regime = regime

            # æ·»åŠ æœ€åä¸€ä¸ªåŒºåŸŸ
            fig.add_vrect(
                x0=start_idx,
                x1=out.index[-1],
                fillcolor=colors[prev_regime],
                opacity=0.2,
                line_width=0,
                row=1,
                col=1,
            )
            fig.add_vrect(
                x0=start_idx,
                x1=out.index[-1],
                fillcolor=colors[prev_regime],
                opacity=0.2,
                line_width=0,
                row=2,
                col=1,
            )

            # æ·»åŠ çŠ¶æ€æ ‡ç­¾
            for regime in ["Bull", "Bear", "Neutral"]:
                regime_data = out[out["regime"] == regime]
                if not regime_data.empty:
                    fig.add_trace(
                        go.Scatter(
                            x=regime_data.index,
                            y=[regime] * len(regime_data),
                            mode="markers",
                            name=regime,
                            marker=dict(color=colors[regime], size=5),
                        ),
                        row=2,
                        col=1,
                    )

            fig.update_layout(
                height=600, showlegend=True, title_text="å…‰å¤§é“¶è¡Œèµ°åŠ¿ä¸å¸‚åœºçŠ¶æ€è¯†åˆ«"
            )
            fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
            fig.update_yaxes(title_text="å¸‚åœºçŠ¶æ€", row=2, col=1)
            fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)

            st.plotly_chart(fig, width="stretch")

        with tab2:
            # æŒ‡æ ‡åˆ†æ
            fig = make_subplots(
                rows=2,
                cols=2,
                subplot_titles=("è‚¡å€ºåˆ©å·®", "å·´è²ç‰¹æŒ‡æ•°", "æ³¢åŠ¨ç‡", "è¶‹åŠ¿æŒ‡æ ‡"),
            )

            # è‚¡å€ºåˆ©å·®
            fig.add_trace(
                go.Scatter(
                    x=out.index,
                    y=out["EBS"],
                    name="è‚¡å€ºåˆ©å·®",
                    line=dict(color="#17becf"),
                ),
                row=1,
                col=1,
            )

            # å·´è²ç‰¹æŒ‡æ•°
            fig.add_trace(
                go.Scatter(
                    x=out.index,
                    y=out["BUFFETT"],
                    name="å·´è²ç‰¹æŒ‡æ•°",
                    line=dict(color="#e377c2"),
                ),
                row=1,
                col=2,
            )

            # æ³¢åŠ¨ç‡
            fig.add_trace(
                go.Scatter(
                    x=out.index, y=out["VOL"], name="æ³¢åŠ¨ç‡", line=dict(color="#7f7f7f")
                ),
                row=2,
                col=1,
            )

            # è¶‹åŠ¿æŒ‡æ ‡
            fig.add_trace(
                go.Scatter(
                    x=out.index,
                    y=out["SPREAD"],
                    name="è¶‹åŠ¿æŒ‡æ ‡",
                    line=dict(color="#bcbd22"),
                ),
                row=2,
                col=2,
            )

            fig.update_layout(height=600, showlegend=True, title_text="å¸‚åœºæŒ‡æ ‡åˆ†æ")
            st.plotly_chart(fig, width="stretch")

        with tab3:
            # ç­–ç•¥è¡¨ç°å¯¹æ¯”
            fig = go.Figure()

            fig.add_trace(
                go.Scatter(
                    x=cum.index,
                    y=cum["BuyHold"],
                    name="ä¹°å…¥æŒæœ‰",
                    line=dict(color="#1f77b4"),
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=cum.index,
                    y=cum["HMM_Strategy"],
                    name="HMMç­–ç•¥",
                    line=dict(color="#ff7f0e"),
                )
            )

            fig.update_layout(
                title="ç­–ç•¥è¡¨ç°å¯¹æ¯”",
                xaxis_title="æ—¥æœŸ",
                yaxis_title="ç´¯è®¡æ”¶ç›Š",
                hovermode="x unified",
                height=500,
            )

            st.plotly_chart(fig, width="stretch")

            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ä¹°å…¥æŒæœ‰å¹´åŒ–æ”¶ç›Š", f"{bh_cagr:.2%}")
            col2.metric("HMMç­–ç•¥å¹´åŒ–æ”¶ç›Š", f"{st_cagr:.2%}")
            col3.metric("ä¹°å…¥æŒæœ‰å¤æ™®æ¯”ç‡", f"{bh_sharp:.2f}")
            col4.metric("HMMç­–ç•¥å¤æ™®æ¯”ç‡", f"{st_sharp:.2f}")

            col5, col6 = st.columns(2)
            col5.metric("ä¹°å…¥æŒæœ‰æœ€å¤§å›æ’¤", f"{bh_mdd:.2%}")
            col6.metric("HMMç­–ç•¥æœ€å¤§å›æ’¤", f"{st_mdd:.2%}")

            # æ˜¾ç¤ºæœ€è¿‘äº¤æ˜“ä¿¡å·
            st.subheader("æœ€è¿‘äº¤æ˜“ä¿¡å·")
            recent_signals = out[["PX", "regime", "position"]].tail(10)
            st.dataframe(
                recent_signals.style.map(
                    lambda x: (
                        "background-color: #2ca02c"
                        if x == "Bull"
                        else (
                            "background-color: #d62728"
                            if x == "Bear"
                            else "background-color: #ff7f0e"
                        )
                    ),
                    subset=["regime"],
                )
            )

        with tab4:
            # çŠ¶æ€ç»Ÿè®¡
            regime_counts = out["regime"].value_counts()
            regime_returns = out.groupby("regime")["log_ret"].mean()
            regime_volatility = out.groupby("regime")["log_ret"].std()
            
            global_logger.info(f"å¸‚åœºçŠ¶æ€åˆ†å¸ƒ: {dict(regime_counts)}")
            global_logger.info(f"å„çŠ¶æ€å¹³å‡æ”¶ç›Š: {dict(regime_returns)}")
            global_logger.info(f"å„çŠ¶æ€æ³¢åŠ¨ç‡: {dict(regime_volatility)}")

            col1, col2 = st.columns(2)

            with col1:
                # ä¿®å¤é¥¼å›¾é—®é¢˜ï¼šå°†Seriesè½¬æ¢ä¸ºåˆ—è¡¨
                fig = px.pie(
                    values=regime_counts.values.tolist(),
                    names=regime_counts.index.tolist(),
                    title="å¸‚åœºçŠ¶æ€åˆ†å¸ƒ",
                    color=regime_counts.index.tolist(),
                    color_discrete_map={
                        "Bull": "#2ca02c",
                        "Bear": "#d62728",
                        "Neutral": "#ff7f0e",
                    },
                )
                st.plotly_chart(fig, width="stretch")

            with col2:
                fig = go.Figure(
                    data=[
                        go.Bar(
                            name="å¹³å‡æ”¶ç›Š",
                            x=regime_returns.index.tolist(),
                            y=regime_returns.values.tolist(),
                            marker_color=["#2ca02c", "#d62728", "#ff7f0e"],
                        ),
                        go.Bar(
                            name="æ³¢åŠ¨ç‡",
                            x=regime_volatility.index.tolist(),
                            y=regime_volatility.values.tolist(),
                            marker_color=["#1f77b4", "#1f77b4", "#1f77b4"],
                        ),
                    ]
                )
                fig.update_layout(title="å„çŠ¶æ€æ”¶ç›Šä¸æ³¢åŠ¨ç‡", barmode="group")
                st.plotly_chart(fig, width="stretch")

            # æ˜¾ç¤ºçŠ¶æ€è½¬æ¢çŸ©é˜µ
            st.subheader("çŠ¶æ€è½¬æ¢çŸ©é˜µ")
            # è®¡ç®—çŠ¶æ€è½¬æ¢
            transitions = []
            prev_state = None
            for state in out["regime"]:
                if prev_state is not None and prev_state != state:
                    transitions.append((prev_state, state))
                prev_state = state
            
            global_logger.info(f"å…±æ£€æµ‹åˆ° {len(transitions)} æ¬¡çŠ¶æ€è½¬æ¢")

            # åˆ›å»ºè½¬æ¢çŸ©é˜µ
            if transitions:
                transition_df = pd.DataFrame(transitions, columns=["From", "To"])
                transition_matrix = pd.crosstab(
                    transition_df["From"], transition_df["To"], normalize="index"
                )
                st.dataframe(transition_matrix.style.background_gradient(cmap="Blues"))
            else:
                st.info("æ²¡æœ‰æ£€æµ‹åˆ°çŠ¶æ€è½¬æ¢")

        # æ˜¾ç¤ºåŸå§‹æ•°æ®
        if st.sidebar.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®"):
            st.subheader("åŸå§‹æ•°æ®")
            st.dataframe(out)

        # æ·»åŠ è¯´æ˜
        st.sidebar.markdown("---")
        st.sidebar.info(
            """
        **ç­–ç•¥è¯´æ˜**:
        - ä½¿ç”¨éšé©¬å°”å¯å¤«æ¨¡å‹è¯†åˆ«å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€
        - ç‰›å¸‚åšå¤šï¼Œç†Šå¸‚åšç©ºï¼Œä¸­æ€§è§‚æœ›
        - åŸºäºå…‰å¤§é“¶è¡Œè‚¡ä»·ã€è‚¡å€ºåˆ©å·®ã€å·´è²ç‰¹æŒ‡æ•°ç­‰å¤šå› å­
        - æ•°æ®æ¥æºï¼šbaostockï¼ˆè‚¡ç¥¨æ•°æ®ï¼‰+ akshareï¼ˆå®è§‚æ•°æ®ï¼‰
        """
        )
        
        # è®°å½•åº”ç”¨è¿è¡Œå®Œæˆ
        global_logger.info("å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«ç³»ç»Ÿè¿è¡Œå®Œæˆ")


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    missing_packages = check_dependencies()

    if missing_packages:
        print("é”™è¯¯: ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for package in missing_packages:
            print(f"  - {package}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install", " ".join(missing_packages))
        sys.exit(1)

    # è®¾ç½®ç¯å¢ƒ
    setup_environment()

    # è¿è¡Œä¸»ç¨‹åº
    main()
