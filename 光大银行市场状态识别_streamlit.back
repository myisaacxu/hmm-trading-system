# å®‰è£…æ‰€éœ€åº“: pip install baostock akshare hmmlearn pandas numpy matplotlib streamlit plotly
import numpy as np
import pandas as pd
import warnings
import baostock as bs
import akshare as ak
from hmmlearn import hmm
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
import joblib
import os
import json
from datetime import datetime

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ç›´æ¥å®šä¹‰get_ebs_dataå‡½æ•°ï¼Œé¿å…è·¯å¾„å¯¼å…¥é—®é¢˜
def get_ebs_data():
    """
    è·å–è‚¡å€ºåˆ©å·®æ•°æ®å¹¶è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    """
    try:
        # ä½¿ç”¨akshareè·å–è‚¡å€ºåˆ©å·®æ•°æ®
        ebs_df = ak.stock_ebs_lg()
        
        if ebs_df.empty:
            st.error("è·å–çš„è‚¡å€ºåˆ©å·®æ•°æ®ä¸ºç©º")
            return None
        
        # é‡å‘½ååˆ—
        ebs_df = ebs_df.rename(columns={
            'æ—¥æœŸ': 'date', 
            'è‚¡å€ºåˆ©å·®': 'ebs_indicator'
        })
        
        # åªä¿ç•™éœ€è¦çš„åˆ—
        ebs_df = ebs_df[['date', 'ebs_indicator']]
        
        # å°†è‚¡å€ºåˆ©å·®è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        ebs_df['ebs_indicator'] = ebs_df['ebs_indicator'] * 100
        
        # å°†åˆ—åæ”¹ä¸ºå°å†™
        ebs_df.columns = ebs_df.columns.str.lower()
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        ebs_df['date'] = pd.to_datetime(ebs_df['date'])
        
        # è®¾ç½®æ—¥æœŸä¸ºç´¢å¼•å¹¶æ’åº
        ebs_df.set_index('date', inplace=True)
        ebs_df = ebs_df.sort_index()
        
        st.success(f"æˆåŠŸè·å–è‚¡å€ºåˆ©å·®æ•°æ®ï¼Œå…± {len(ebs_df)} æ¡è®°å½•")
        st.info(f"è‚¡å€ºåˆ©å·®èŒƒå›´: {ebs_df['ebs_indicator'].min():.2f}% - {ebs_df['ebs_indicator'].max():.2f}%")
        
        return ebs_df
        
    except Exception as e:
        st.error(f"è·å–è‚¡å€ºåˆ©å·®æ•°æ®æ—¶å‡ºé”™: {e}")
        return None

# å®šä¹‰get_buffett_indexå‡½æ•°
def get_buffett_index():
    """
    è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®å¹¶è®¡ç®—å·´è²ç‰¹æŒ‡æ•°
    """
    try:
        st.info("æ­£åœ¨è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®...")
        buffett_df = ak.stock_buffett_index_lg()
        
        # é‡å‘½ååˆ—
        buffett_df.rename(columns={'æ—¥æœŸ': 'date'}, inplace=True)
        buffett_df['date'] = pd.to_datetime(buffett_df['date'])
        buffett_df.set_index('date', inplace=True)
        buffett_df.sort_index(inplace=True)
        
        # æ‰‹åŠ¨è®¡ç®—å·´è²ç‰¹æŒ‡æ•°ï¼šæ€»å¸‚å€¼/GDP * 100
        buffett_df['buffett_index'] = (buffett_df['æ€»å¸‚å€¼'] / buffett_df['GDP']) * 100
        
        st.success(f"æˆåŠŸè·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®ï¼Œå…± {len(buffett_df)} æ¡è®°å½•")
        st.info(f"å·´è²ç‰¹æŒ‡æ•°èŒƒå›´: {buffett_df['buffett_index'].min():.2f} - {buffett_df['buffett_index'].max():.2f}")
        
        # åªè¿”å›å·´è²ç‰¹æŒ‡æ•°åˆ—
        result_series = buffett_df['buffett_index'].copy()
        result_series.name = 'buffett_index'
        
        return result_series
        
    except Exception as e:
        st.error(f"è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®æ—¶å‡ºé”™: {e}")
        return None

# å…‰å¤§é“¶è¡Œæ•°æ®è·å–å‡½æ•°
def get_cebbank_data(start_date, end_date=None):
    """
    ä½¿ç”¨baostockè·å–å…‰å¤§é“¶è¡Œè‚¡ç¥¨æ•°æ®
    """
    try:
        st.info("æ­£åœ¨è·å–å…‰å¤§é“¶è¡Œå†å²æ•°æ®...")
        
        # ç™»å½•baostock
        lg = bs.login()
        if lg.error_code != '0':
            st.error(f"baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None
        
        # å…‰å¤§é“¶è¡Œè‚¡ç¥¨ä»£ç 
        stock_code = "sh.601818"
        
        # è®¾ç½®æŸ¥è¯¢å­—æ®µ
        fields = "date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,pctChg"
        
        # å¦‚æœæœªæä¾›ç»“æŸæ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        
        # æŸ¥è¯¢å†å²è¡Œæƒ…æ•°æ®
        rs = bs.query_history_k_data_plus(
            code=stock_code,
            fields=fields,
            start_date=start_date,
            end_date=end_date,
            frequency="d",  # æ—¥çº¿
            adjustflag="3"  # å‰å¤æƒ
        )
        
        if rs.error_code != '0':
            st.error(f"æŸ¥è¯¢å…‰å¤§é“¶è¡Œå†å²æ•°æ®å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None
        
        # å°†æ•°æ®è½¬æ¢ä¸ºDataFrame
        data_list = []
        while (rs.error_code == '0') & rs.next():
            data_list.append(rs.get_row_data())
        
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # æ•°æ®ç±»å‹è½¬æ¢
        numeric_columns = ['open', 'high', 'low', 'close', 'preclose', 'volume', 'amount', 'turn', 'pctChg']
        
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # æ—¥æœŸè½¬æ¢
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        df.set_index('date', inplace=True)
        
        # ç™»å‡º
        bs.logout()
        
        st.success(f"æˆåŠŸè·å–å…‰å¤§é“¶è¡Œæ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        st.info(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min().strftime('%Y-%m-%d')} åˆ° {df.index.max().strftime('%Y-%m-%d')}")
        
        return df
        
    except Exception as e:
        st.error(f"è·å–å…‰å¤§é“¶è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
        if 'bs' in locals():
            try:
                bs.logout()
            except:
                pass
        return None

# å¯é‡ç°æ€§è®¾ç½®
RANDOM_STATE = 42

# æ¨¡å‹ç®¡ç†å‡½æ•°
def save_model(model, performance_metrics, model_name=None):
    """ä¿å­˜æ¨¡å‹å’Œæ€§èƒ½æŒ‡æ ‡"""
    models_dir = "trycode2/models"
    os.makedirs(models_dir, exist_ok=True)
    
    if model_name is None:
        model_name = f"hmm_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    model_path = os.path.join(models_dir, f"{model_name}.joblib")
    metrics_path = os.path.join(models_dir, f"{model_name}_metrics.json")
    
    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, model_path)
    
    # ä¿å­˜æ€§èƒ½æŒ‡æ ‡
    with open(metrics_path, 'w') as f:
        json.dump(performance_metrics, f, indent=2)
    
    return model_name

def load_model(model_name):
    """åŠ è½½æ¨¡å‹å’Œæ€§èƒ½æŒ‡æ ‡"""
    models_dir = "trycode2/models"
    model_path = os.path.join(models_dir, f"{model_name}.joblib")
    metrics_path = os.path.join(models_dir, f"{model_name}_metrics.json")
    
    if not os.path.exists(model_path):
        return None, None
    
    model = joblib.load(model_path)
    
    if os.path.exists(metrics_path):
        with open(metrics_path, 'r') as f:
            metrics = json.load(f)
    else:
        metrics = {}
    
    return model, metrics

def list_saved_models():
    """åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„æ¨¡å‹"""
    models_dir = "trycode2/models"
    if not os.path.exists(models_dir):
        return []
    
    models = []
    for file in os.listdir(models_dir):
        if file.endswith('.joblib'):
            model_name = file.replace('.joblib', '')
            metrics_file = os.path.join(models_dir, f"{model_name}_metrics.json")
            if os.path.exists(metrics_file):
                with open(metrics_file, 'r') as f:
                    metrics = json.load(f)
                models.append({
                    'name': model_name,
                    'cagr': metrics.get('cagr', 0),
                    'sharpe': metrics.get('sharpe', 0),
                    'mdd': metrics.get('mdd', 0),
                    'date': metrics.get('date', '')
                })
    
    # æŒ‰å¤æ™®æ¯”ç‡æ’åº
    models.sort(key=lambda x: x['sharpe'], reverse=True)
    return models

# ä¾§è¾¹æ é…ç½®å‚æ•°
st.sidebar.header("ç­–ç•¥å‚æ•°é…ç½®")

asset = st.sidebar.selectbox("é€‰æ‹©èµ„äº§", ["å…‰å¤§é“¶è¡Œ(601818)"], index=0)
start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", pd.to_datetime("2010-01-01"))
n_states = st.sidebar.slider("çŠ¶æ€æ•°é‡", 2, 6, 3)
min_len = st.sidebar.slider("æœ€å°çŠ¶æ€æŒç»­æ—¶é—´", 5, 30, 15)
stickiness = st.sidebar.slider("çŠ¶æ€ç²˜æ€§", 1.0, 20.0, 8.0)

# é“¶è¡Œè‚¡ä¸“ç”¨å‚æ•°
st.sidebar.markdown("---")
st.sidebar.header("é“¶è¡Œè‚¡ä¸“ç”¨å‚æ•°")
vol_window = st.sidebar.slider("æ³¢åŠ¨ç‡è®¡ç®—çª—å£", 10, 60, 30)
ma_short = st.sidebar.slider("çŸ­æœŸå‡çº¿çª—å£", 10, 50, 20)
ma_long = st.sidebar.slider("é•¿æœŸå‡çº¿çª—å£", 50, 200, 100)

start = start_date.strftime("%Y%m%d")
end = None

# æ¨¡å‹ç®¡ç†é€‰é¡¹
st.sidebar.markdown("---")
st.sidebar.header("æ¨¡å‹ç®¡ç†")

# æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡å‹
saved_models = list_saved_models()
if saved_models:
    st.sidebar.subheader("å·²ä¿å­˜çš„æ¨¡å‹")
    best_model = saved_models[0]  # æŒ‰å¤æ™®æ¯”ç‡æ’åºåçš„æœ€ä½³æ¨¡å‹
    st.sidebar.info(f"æœ€ä½³æ¨¡å‹: {best_model['name']}")
    st.sidebar.metric("æœ€ä½³å¤æ™®æ¯”ç‡", f"{best_model['sharpe']:.2f}")
    st.sidebar.metric("æœ€ä½³å¹´åŒ–æ”¶ç›Š", f"{best_model['cagr']:.2%}")
    
    # æ¨¡å‹æ¯”è¾ƒé€‰é¡¹
    compare_models = st.sidebar.checkbox("ä¸æœ€ä½³æ¨¡å‹æ¯”è¾ƒ")
else:
    compare_models = False
    st.sidebar.info("æš‚æ— ä¿å­˜çš„æ¨¡å‹")

# è‡ªåŠ¨ä¿å­˜é€‰é¡¹
auto_save = st.sidebar.checkbox("è‡ªåŠ¨ä¿å­˜è¡¨ç°æ›´å¥½çš„æ¨¡å‹", value=True)
save_threshold = st.sidebar.slider("ä¿å­˜é˜ˆå€¼ï¼ˆå¤æ™®æ¯”ç‡æå‡ï¼‰", 0.0, 1.0, 0.1)

# æ˜¾ç¤ºè¿›åº¦
with st.spinner('æ­£åœ¨è·å–æ•°æ®å¹¶è®¡ç®—...'):
    # ä¸‹è½½å…‰å¤§é“¶è¡Œæ•°æ®
    df_cebbank = get_cebbank_data(start_date.strftime("%Y-%m-%d"), end)
    
    if df_cebbank is None or df_cebbank.empty:
        st.error("æ— æ³•è·å–å…‰å¤§é“¶è¡Œæ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ—¥æœŸèŒƒå›´")
        st.stop()
    
    px_series = df_cebbank["close"].rename("PX")

    # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
    px_series = px_series[~px_series.index.duplicated(keep='first')]

    # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡ç‰¹å¾ï¼ˆé’ˆå¯¹é“¶è¡Œè‚¡ä¼˜åŒ–ï¼‰
    lr = np.log(px_series).diff().fillna(0.0)  # å¯¹æ•°æ”¶ç›Šç‡
    vol = lr.rolling(vol_window, min_periods=1).std().fillna(0.0)  # å¯è°ƒæ³¢åŠ¨ç‡çª—å£
    ma_short = px_series.rolling(ma_short).mean().bfill()
    ma_long = px_series.rolling(ma_long).mean().bfill()
    spread = ((ma_short - ma_long) / ma_long).fillna(0.0)  # å¯è°ƒè¶‹åŠ¿æŒ‡æ ‡

    # è·å–è‚¡å€ºåˆ©å·®æ•°æ®
    ebs_data = get_ebs_data()
    if ebs_data is not None:
        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
        ebs_data = ebs_data[~ebs_data.index.duplicated(keep='first')]
        ebs_data = ebs_data.reindex(px_series.index, method='ffill')  # å¯¹é½æ—¥æœŸç´¢å¼•
    else:
        # å¦‚æœè·å–å¤±è´¥ï¼Œåˆ›å»ºç©ºçš„è‚¡å€ºåˆ©å·®åˆ—
        ebs_data = pd.Series(0.0, index=px_series.index, name='ebs_indicator')

    # è·å–å·´è²ç‰¹æŒ‡æ•°æ•°æ®
    buffett_data = get_buffett_index()
    if buffett_data is not None:
        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
        buffett_data = buffett_data[~buffett_data.index.duplicated(keep='first')]
        buffett_data = buffett_data.reindex(px_series.index, method='ffill')  # å¯¹é½æ—¥æœŸç´¢å¼•
    else:
        # å¦‚æœè·å–å¤±è´¥ï¼Œåˆ›å»ºç©ºçš„å·´è²ç‰¹æŒ‡æ•°åˆ—
        buffett_data = pd.Series(0.0, index=px_series.index, name='buffett_index')

    # åˆ›å»ºç‰¹å¾æ•°æ®æ¡†
    df = pd.DataFrame({
        "PX": px_series,
        "VOL": vol,
        "SPREAD": spread,
        "EBS": ebs_data["ebs_indicator"] if isinstance(ebs_data, pd.DataFrame) else ebs_data,
        "BUFFETT": buffett_data["buffett_index"] if isinstance(buffett_data, pd.DataFrame) else buffett_data
    }).dropna()

    # ç¡®ä¿æ—¥æœŸç´¢å¼•å¯¹é½
    df = df.sort_index()

    # è®¾è®¡çŸ©é˜µï¼ˆè¡Œå¯¹åº” df.indexï¼‰
    X = np.column_stack([
        np.log(df["PX"]).diff().fillna(0.0).values,  # å¯¹æ•°æ”¶ç›Šç‡
        df["VOL"].values,  # æ³¢åŠ¨ç‡
        df["SPREAD"].values,  # è¶‹åŠ¿æŒ‡æ ‡
        df["EBS"].values,  # è‚¡å€ºåˆ©å·®
        df["BUFFETT"].values  # å·´è²ç‰¹æŒ‡æ•°
    ])
    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

    # å¯é€‰ï¼šZ-åˆ†æ•°æ ‡å‡†åŒ–ï¼Œæé«˜çŠ¶æ€åŒºåˆ†åº¦
    X_mean = X.mean(axis=0, keepdims=True)
    X_std = X.std(axis=0, keepdims=True) + 1e-12
    Xz = (X - X_mean) / X_std

    # 3. æ ¸å¿ƒé€»è¾‘ â€” HMM ç±»ä¸å¹³æ»‘å¤„ç†
    class HMMRegimeDetector:
        def __init__(self, n_states=4, covariance_type="diag", n_iter=300, tol=1e-4, random_state=None):
            self.model = hmm.GaussianHMM(
                n_components=n_states,
                covariance_type=covariance_type,
                n_iter=n_iter,
                tol=tol,
                random_state=random_state
            )
            self.n_states = n_states
        
        @staticmethod
        def enforce_min_duration(labels, min_len=10):
            """åˆå¹¶çŸ­çŠ¶æ€è¿è¡Œï¼ˆ< min_lenï¼‰åˆ°è¾ƒé•¿çš„ç›¸é‚»çŠ¶æ€"""
            s = np.array(labels, copy=True)
            n = len(s); i = 0
            while i < n:
                j = i + 1
                while j < n and s[j] == s[i]: j += 1
                run_len = j - i
                if run_len < min_len:
                    left = s[i-1] if i > 0 else None
                    right = s[j] if j < n else None
                    if left is None and right is not None:
                        s[i:j] = right
                    elif right is None and left is not None:
                        s[i:j] = left
                    elif left is not None and right is not None:
                        # æ¯”è¾ƒç›¸é‚»è¿è¡Œçš„é•¿åº¦
                        L = i-1
                        while L-1 >= 0 and s[L-1] == left: L -= 1
                        left_len = i - L
                        R = j
                        while R+1 < n and s[R+1] == right: R += 1
                        right_len = R - j + 1
                        s[i:j] = left if left_len >= right_len else right
                i = j
            return s
        
        def fit(self, X):
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore")
                self.model.fit(X)
            return self
        
        def make_sticky(self, strength=10.0):
            """é€šè¿‡å¢å¼ºè½¬ç§»çŸ©é˜µå¯¹è§’çº¿ä½¿çŠ¶æ€æ›´å€¾å‘äºä¿æŒä¸å˜"""
            A = self.model.transmat_
            A = A + strength * np.eye(self.n_states)
            self.model.transmat_ = A / A.sum(axis=1, keepdims=True)
            return self
        
        def predict(self, X, min_len=10, sticky_strength=None):
            if sticky_strength is not None:
                self.make_sticky(sticky_strength)
            states = self.model.predict(X)
            states = self.enforce_min_duration(states, min_len=min_len)
            proba = self.model.predict_proba(X)
            return states, proba

    # 4. æ‰§è¡Œå’Œç»“æœï¼ˆè®­ç»ƒã€æ ‡è®°ã€ç»˜å›¾ã€ç®€å•å›æµ‹ï¼‰
    # åœ¨æ ‡å‡†åŒ–ç‰¹å¾ä¸Šè®­ç»ƒ HMM
    detector = HMMRegimeDetector(n_states=n_states).fit(Xz)

    # ä½¿ç”¨ç²˜æ€§å’Œæœ€å°æŒç»­æ—¶é—´å¹³æ»‘é¢„æµ‹çŠ¶æ€
    states, proba = detector.predict(Xz, min_len=min_len, sticky_strength=stickiness)

    # ç»„è£…è¾“å‡ºæ•°æ®æ¡†
    out = df.copy()
    out["log_ret"] = np.log(df["PX"]).diff().fillna(0.0)
    out["state"] = states

    # æŒ‰å¹³å‡æ”¶ç›Šç‡æ’åºçŠ¶æ€å¹¶æ˜ å°„åˆ°å¸‚åœºçŠ¶æ€
    state_means = out.groupby("state")["log_ret"].mean().sort_values(ascending=False)
    ranked = state_means.index.tolist()
    labels = {ranked[0]: "Bull", ranked[-1]: "Bear"}
    for s in set(range(n_states)) - set(labels):
        labels[s] = "Neutral"
    out["regime"] = out["state"].map(labels)

    # ç®€å•çŠ¶æ€äº¤æ˜“å›æµ‹ï¼ˆä»…ç”¨äºç›´è§‚ç†è§£ï¼Œéæ‰§è¡Œçº§åˆ«ï¼‰
    # ç‰›å¸‚åšå¤šï¼Œç†Šå¸‚åšç©ºï¼Œä¸­æ€§å¸‚åœºè§‚æœ›ï¼›ç¬¬äºŒå¤©æ‰§è¡Œäº¤æ˜“ï¼ˆç§»ä½æŒä»“ï¼‰
    out["position"] = 0
    out.loc[out["regime"]=="Bull", "position"] = 1
    out.loc[out["regime"]=="Bear", "position"] = -1

    # åº”ç”¨æ¬¡æ—¥æ‰§è¡Œ
    out["position"] = out["position"].shift(1).fillna(0)

    # ç­–ç•¥å¯¹æ•°æ”¶ç›Šç‡å’Œç´¯ç§¯å¢é•¿ï¼ˆå¯¹æ•°/æŒ‡æ•°ç”¨äºæ•°å€¼ç¨³å®šæ€§ï¼‰
    out["strat_lr"] = out["position"] * out["log_ret"]
    cum = np.exp(out[["log_ret","strat_lr"]].cumsum())
    cum.columns = ["BuyHold", "HMM_Strategy"]

    # ç®€å•æŒ‡æ ‡è®¡ç®—
    def sharpe(x, periods=252):
        mu, sd = x.mean(), x.std()
        return (mu / sd) * np.sqrt(periods) if sd > 0 else np.nan

    def max_drawdown(series):
        rollmax = series.cummax()
        dd = series/rollmax - 1.0
        return dd.min()

    bh_cagr = cum["BuyHold"].iloc[-1]**(252/len(out)) - 1
    st_cagr = cum["HMM_Strategy"].iloc[-1]**(252/len(out)) - 1
    bh_sharp = sharpe(out["log_ret"])
    st_sharp = sharpe(out["strat_lr"])
    bh_mdd = max_drawdown(cum["BuyHold"])
    st_mdd = max_drawdown(cum["HMM_Strategy"])

    # æ¨¡å‹ä¿å­˜å’Œæ¯”è¾ƒé€»è¾‘
    current_performance = {
        'cagr': st_cagr,
        'sharpe': st_sharp,
        'mdd': st_mdd,
        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'params': {
            'n_states': n_states,
            'min_len': min_len,
            'stickiness': stickiness,
            'start_date': start_date.strftime('%Y-%m-%d')
        }
    }

    # ä¸æœ€ä½³æ¨¡å‹æ¯”è¾ƒ
    best_model_sharpe = 0
    if saved_models:
        best_model_sharpe = saved_models[0]['sharpe']
        if compare_models:
            st.sidebar.markdown("---")
            st.sidebar.subheader("æ¨¡å‹æ¯”è¾ƒç»“æœ")
            if st_sharp > best_model_sharpe + save_threshold:
                st.sidebar.success(f"ğŸ¯ å½“å‰æ¨¡å‹è¡¨ç°æ›´å¥½ï¼å¤æ™®æ¯”ç‡: {st_sharp:.2f} vs {best_model_sharpe:.2f}")
            else:
                st.sidebar.info(f"ğŸ“Š æœ€ä½³æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚å¤æ™®æ¯”ç‡: {best_model_sharpe:.2f} vs {st_sharp:.2f}")

    # è‡ªåŠ¨ä¿å­˜è¡¨ç°æ›´å¥½çš„æ¨¡å‹
    if auto_save and st_sharp > best_model_sharpe + save_threshold:
        model_name = save_model(detector, current_performance)
        st.sidebar.success(f"ğŸ’¾ å·²ä¿å­˜æ–°æ¨¡å‹: {model_name}")
        st.sidebar.metric("ä¿å­˜çš„å¤æ™®æ¯”ç‡", f"{st_sharp:.2f}")

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ¦ å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€è¯†åˆ«ç³»ç»Ÿ")
st.markdown("åŸºäºéšé©¬å°”å¯å¤«æ¨¡å‹(HMM)çš„é“¶è¡Œè‚¡å¸‚åœºçŠ¶æ€è¯†åˆ«ä¸äº¤æ˜“ç­–ç•¥")

# æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
col1, col2, col3, col4 = st.columns(4)
col1.metric("å½“å‰å¸‚åœºçŠ¶æ€", out["regime"].iloc[-1])
col2.metric("å…‰å¤§é“¶è¡Œä»·æ ¼", f"{out['PX'].iloc[-1]:.2f}")
col3.metric("è‚¡å€ºåˆ©å·®", f"{out['EBS'].iloc[-1]:.2f}%")
col4.metric("å·´è²ç‰¹æŒ‡æ•°", f"{out['BUFFETT'].iloc[-1]:.2f}")

# åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºä¸åŒå›¾è¡¨
tab1, tab2, tab3, tab4 = st.tabs(["å…‰å¤§é“¶è¡Œèµ°åŠ¿", "æŒ‡æ ‡åˆ†æ", "ç­–ç•¥è¡¨ç°", "çŠ¶æ€ç»Ÿè®¡"])

with tab1:
    # å…‰å¤§é“¶è¡Œèµ°åŠ¿ä¸å¸‚åœºçŠ¶æ€
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, 
                       vertical_spacing=0.05, subplot_titles=('å…‰å¤§é“¶è¡Œä»·æ ¼', 'å¸‚åœºçŠ¶æ€'))
    
    # æ·»åŠ ä»·æ ¼çº¿
    fig.add_trace(go.Scatter(x=out.index, y=out["PX"], name="å…‰å¤§é“¶è¡Œ", line=dict(color='#1f77b4')), row=1, col=1)
    
    # æ·»åŠ å¸‚åœºçŠ¶æ€èƒŒæ™¯
    colors = {"Bull": "#2ca02c", "Bear": "#d62728", "Neutral": "#ff7f0e"}
    prev_regime = None
    start_idx = out.index[0]
    
    for i, (date, regime) in enumerate(out["regime"].items()):
        if prev_regime is None:
            prev_regime = regime
            continue
            
        if regime != prev_regime:
            # æ·»åŠ çŸ©å½¢åŒºåŸŸ
            fig.add_vrect(x0=start_idx, x1=date, 
                         fillcolor=colors[prev_regime], opacity=0.2, 
                         line_width=0, row=1, col=1)
            fig.add_vrect(x0=start_idx, x1=date, 
                         fillcolor=colors[prev_regime], opacity=0.2, 
                         line_width=0, row=2, col=1)
            start_idx = date
            prev_regime = regime
    
    # æ·»åŠ æœ€åä¸€ä¸ªåŒºåŸŸ
    fig.add_vrect(x0=start_idx, x1=out.index[-1], 
                 fillcolor=colors[prev_regime], opacity=0.2, 
                 line_width=0, row=1, col=1)
    fig.add_vrect(x0=start_idx, x1=out.index[-1], 
                 fillcolor=colors[prev_regime], opacity=0.2, 
                 line_width=0, row=2, col=1)
    
    # æ·»åŠ çŠ¶æ€æ ‡ç­¾
    for regime in ["Bull", "Bear", "Neutral"]:
        regime_data = out[out["regime"] == regime]
        if not regime_data.empty:
            fig.add_trace(go.Scatter(
                x=regime_data.index, 
                y=[regime] * len(regime_data), 
                mode='markers', 
                name=regime,
                marker=dict(color=colors[regime], size=5)
            ), row=2, col=1)
    
    fig.update_layout(height=600, showlegend=True, title_text="å…‰å¤§é“¶è¡Œèµ°åŠ¿ä¸å¸‚åœºçŠ¶æ€è¯†åˆ«")
    fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
    fig.update_yaxes(title_text="å¸‚åœºçŠ¶æ€", row=2, col=1)
    fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
    
    st.plotly_chart(fig, width='stretch')

with tab2:
    # æŒ‡æ ‡åˆ†æ
    fig = make_subplots(rows=2, cols=2, subplot_titles=('è‚¡å€ºåˆ©å·®', 'å·´è²ç‰¹æŒ‡æ•°', 'æ³¢åŠ¨ç‡', 'è¶‹åŠ¿æŒ‡æ ‡'))
    
    # è‚¡å€ºåˆ©å·®
    fig.add_trace(go.Scatter(x=out.index, y=out["EBS"], name="è‚¡å€ºåˆ©å·®", line=dict(color='#17becf')), row=1, col=1)
    
    # å·´è²ç‰¹æŒ‡æ•°
    fig.add_trace(go.Scatter(x=out.index, y=out["BUFFETT"], name="å·´è²ç‰¹æŒ‡æ•°", line=dict(color='#e377c2')), row=1, col=2)
    
    # æ³¢åŠ¨ç‡
    fig.add_trace(go.Scatter(x=out.index, y=out["VOL"], name="æ³¢åŠ¨ç‡", line=dict(color='#7f7f7f')), row=2, col=1)
    
    # è¶‹åŠ¿æŒ‡æ ‡
    fig.add_trace(go.Scatter(x=out.index, y=out["SPREAD"], name="è¶‹åŠ¿æŒ‡æ ‡", line=dict(color='#bcbd22')), row=2, col=2)
    
    fig.update_layout(height=600, showlegend=True, title_text="å¸‚åœºæŒ‡æ ‡åˆ†æ")
    st.plotly_chart(fig, width='stretch')

with tab3:
    # ç­–ç•¥è¡¨ç°å¯¹æ¯”
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(x=cum.index, y=cum["BuyHold"], name="ä¹°å…¥æŒæœ‰", line=dict(color='#1f77b4')))
    fig.add_trace(go.Scatter(x=cum.index, y=cum["HMM_Strategy"], name="HMMç­–ç•¥", line=dict(color='#ff7f0e')))
    
    fig.update_layout(
        title="ç­–ç•¥è¡¨ç°å¯¹æ¯”",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="ç´¯è®¡æ”¶ç›Š",
        hovermode="x unified",
        height=500
    )
    
    st.plotly_chart(fig, width='stretch')
    
    # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ä¹°å…¥æŒæœ‰å¹´åŒ–æ”¶ç›Š", f"{bh_cagr:.2%}")
    col2.metric("HMMç­–ç•¥å¹´åŒ–æ”¶ç›Š", f"{st_cagr:.2%}")
    col3.metric("ä¹°å…¥æŒæœ‰å¤æ™®æ¯”ç‡", f"{bh_sharp:.2f}")
    col4.metric("HMMç­–ç•¥å¤æ™®æ¯”ç‡", f"{st_sharp:.2f}")
    
    col5, col6, col7, col8 = st.columns(4)
    col5.metric("ä¹°å…¥æŒæœ‰æœ€å¤§å›æ’¤", f"{bh_mdd:.2%}")
    col6.metric("HMMç­–ç•¥æœ€å¤§å›æ’¤", f"{st_mdd:.2%}")
    
    # æ˜¾ç¤ºæœ€è¿‘äº¤æ˜“ä¿¡å·
    st.subheader("æœ€è¿‘äº¤æ˜“ä¿¡å·")
    recent_signals = out[["PX", "regime", "position"]].tail(10)
    st.dataframe(recent_signals.style.map(
        lambda x: 'background-color: #2ca02c' if x == "Bull" else ('background-color: #d62728' if x == "Bear" else 'background-color: #ff7f0e'), 
        subset=['regime']
    ))

with tab4:
    # çŠ¶æ€ç»Ÿè®¡
    regime_counts = out["regime"].value_counts()
    regime_returns = out.groupby("regime")["log_ret"].mean()
    regime_volatility = out.groupby("regime")["log_ret"].std()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ä¿®å¤é¥¼å›¾é—®é¢˜ï¼šå°†Seriesè½¬æ¢ä¸ºåˆ—è¡¨
        fig = px.pie(values=regime_counts.values.tolist(), 
                    names=regime_counts.index.tolist(), 
                    title="å¸‚åœºçŠ¶æ€åˆ†å¸ƒ", 
                    color=regime_counts.index.tolist(),
                    color_discrete_map={"Bull": "#2ca02c", "Bear": "#d62728", "Neutral": "#ff7f0e"})
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        fig = go.Figure(data=[
            go.Bar(name='å¹³å‡æ”¶ç›Š', x=regime_returns.index.tolist(), y=regime_returns.values.tolist(), 
                  marker_color=['#2ca02c', '#d62728', '#ff7f0e']),
            go.Bar(name='æ³¢åŠ¨ç‡', x=regime_volatility.index.tolist(), y=regime_volatility.values.tolist(), 
                  marker_color=['#1f77b4', '#1f77b4', '#1f77b4'])
        ])
        fig.update_layout(title="å„çŠ¶æ€æ”¶ç›Šä¸æ³¢åŠ¨ç‡", barmode='group')
        st.plotly_chart(fig, width='stretch')
    
    # æ˜¾ç¤ºçŠ¶æ€è½¬æ¢çŸ©é˜µ
    st.subheader("çŠ¶æ€è½¬æ¢çŸ©é˜µ")
    # è®¡ç®—çŠ¶æ€è½¬æ¢
    transitions = []
    prev_state = None
    for state in out["regime"]:
        if prev_state is not None and prev_state != state:
            transitions.append((prev_state, state))
        prev_state = state
    
    # åˆ›å»ºè½¬æ¢çŸ©é˜µ
    if transitions:
        transition_df = pd.DataFrame(transitions, columns=['From', 'To'])
        transition_matrix = pd.crosstab(transition_df['From'], transition_df['To'], normalize='index')
        st.dataframe(transition_matrix.style.background_gradient(cmap='Blues'))
    else:
        st.info("æ²¡æœ‰æ£€æµ‹åˆ°çŠ¶æ€è½¬æ¢")

# æ˜¾ç¤ºåŸå§‹æ•°æ®
if st.sidebar.checkbox("æ˜¾ç¤ºåŸå§‹æ•°æ®"):
    st.subheader("åŸå§‹æ•°æ®")
    st.dataframe(out)

# æ·»åŠ è¯´æ˜
st.sidebar.markdown("---")
st.sidebar.info("""
**ç­–ç•¥è¯´æ˜**:
- ä½¿ç”¨éšé©¬å°”å¯å¤«æ¨¡å‹è¯†åˆ«å…‰å¤§é“¶è¡Œå¸‚åœºçŠ¶æ€
- ç‰›å¸‚åšå¤šï¼Œç†Šå¸‚åšç©ºï¼Œä¸­æ€§è§‚æœ›
- åŸºäºå…‰å¤§é“¶è¡Œè‚¡ä»·ã€è‚¡å€ºåˆ©å·®ã€å·´è²ç‰¹æŒ‡æ•°ç­‰å¤šå› å­
- æ•°æ®æ¥æºï¼šbaostockï¼ˆè‚¡ç¥¨æ•°æ®ï¼‰+ akshareï¼ˆå®è§‚æ•°æ®ï¼‰
""")